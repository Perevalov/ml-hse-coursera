{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "features = pd.read_csv('./features.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Названия признаков, имеющих пропуски: \n",
      "first_blood_time\n",
      "first_blood_team\n",
      "first_blood_player1\n",
      "first_blood_player2\n",
      "radiant_bottle_time\n",
      "radiant_courier_time\n",
      "radiant_flying_courier_time\n",
      "radiant_first_ward_time\n",
      "dire_bottle_time\n",
      "dire_courier_time\n",
      "dire_flying_courier_time\n",
      "dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "counts = features.count()\n",
    "max_count = max(counts)\n",
    "print(\"Названия признаков, имеющих пропуски: \")\n",
    "for i, count in enumerate(counts):\n",
    "    if count < max_count:\n",
    "        print(features.columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки first_blood_time, first_blood_team, first_blood_player1, first_blood_player2 могут быть пропущенные, потому что не в каждой игре происходит первое убийство до 5 минуты. Тоже самое для остальных признаков: покупка курьера, ботла или вардов, также может не произойти за это время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Как называется столбец, содержащий целевую переменную?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "radiant_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.values[:,:-6]\n",
    "y = features.values[:, -5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество деревьев: 10; качество: 0.6643877206345742, время: 34\n",
      "Количество деревьев: 15; качество: 0.6757420237293614, время: 52\n",
      "Количество деревьев: 20; качество: 0.6828535735340822, время: 64\n",
      "Количество деревьев: 25; качество: 0.6868481585275605, время: 87\n",
      "Количество деревьев: 30; качество: 0.6894962060591201, время: 96\n",
      "Количество деревьев: 35; качество: 0.6919738231779972, время: 112\n",
      "Количество деревьев: 40; качество: 0.6941311214730337, время: 132\n",
      "Количество деревьев: 45; качество: 0.6958955138922052, время: 139\n",
      "Количество деревьев: 50; качество: 0.6974548316948366, время: 153\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "selector = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = GradientBoostingClassifier(n_estimators=250, random_state=241)\n",
    "\n",
    "scores = []\n",
    "times = [] \n",
    "\n",
    "for i in range(10,51,5):\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, random_state=241)\n",
    "    \n",
    "    sum_score = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    for train_index, test_index in selector.split(X):\n",
    "        clf.fit(X[train_index],y[train_index])               \n",
    "        pred = clf.predict_proba(X[test_index])[:, 1]        \n",
    "        score = roc_auc_score(y[test_index], pred)\n",
    "        sum_score += score\n",
    "        \n",
    "    time = datetime.datetime.now() - start_time\n",
    "    times.append(time)\n",
    "    \n",
    "    scores.append(sum_score / 5)\n",
    "\n",
    "for i, s in enumerate(scores):\n",
    "    print(f\"Количество деревьев: {(i + 2) * 5}; качество: {s}, время: {times[i].seconds}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Какое качество при этом получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кросс-валидация для 30 деревьев проводилась - 96 секунд. При этом получилось качество 0.689.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Кросс-валидация для 30 деревьев проводилась - {times[4].seconds} секунд. При этом получилось качество {scores[4]:.3}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование более 30 деревьев в градиентом бустинге не имеет особого смысла, так как возможно переобучение. Чтобы ускорить обучение, можно уменьшит максмимальную глубину деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С: 1e-05; качество: 0.695120379847076, время: 3\n",
      "С: 0.0001; качество: 0.7112501143920594, время: 5\n",
      "С: 0.001; качество: 0.7161802463683578, время: 10\n",
      "С: 0.01; качество: 0.716341462186996, время: 13\n",
      "С: 0.1; качество: 0.7163100836533356, время: 14\n",
      "С: 1.0; качество: 0.716306583645544, время: 14\n",
      "С: 10.0; качество: 0.7163063399602339, время: 14\n",
      "С: 100.0; качество: 0.7163062657792337, время: 14\n",
      "С: 1000.0; качество: 0.7163062636530346, время: 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = []\n",
    "times = []\n",
    "coefs = np.power(10.0, np.arange(-5, 4))\n",
    "\n",
    "for i in coefs:\n",
    "    clf = LogisticRegression(C=i, random_state=241)\n",
    "    \n",
    "    sum_score = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for train_index, test_index in selector.split(X):\n",
    "        clf.fit(scaled_X[train_index],y[train_index])               \n",
    "        pred = clf.predict_proba(scaled_X[test_index])[:, 1]        \n",
    "        score = roc_auc_score(y[test_index], pred)\n",
    "        sum_score += score\n",
    "        \n",
    "    time = datetime.datetime.now() - start_time\n",
    "    times.append(time)\n",
    "    \n",
    "    scores.append(sum_score / 5)\n",
    "    \n",
    "for i, s in enumerate(scores):\n",
    "    print(f\"С: {coefs[i]}; качество: {s}, время: {times[i].seconds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее качество 0.716. Немного лучше чем у градиентного бустинга, потому что линейные методы работают лучше с большим числом признаков. Работает гораздо быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_nocat = scaled_X\n",
    "for i in range(9,-1,-1):\n",
    "    scaled_X_nocat = np.delete(scaled_X_nocat, 2 + i * 8, 1)\n",
    "scaled_X_nocat = np.delete(scaled_X_nocat, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С: 1e-05; качество: 0.6950569329910983, время: 2\n",
      "С: 0.0001; качество: 0.7112483906159717, время: 4\n",
      "С: 0.001; качество: 0.7162355910206267, время: 9\n",
      "С: 0.01; качество: 0.7164009506527343, время: 12\n",
      "С: 0.1; качество: 0.7163737844721112, время: 13\n",
      "С: 1.0; качество: 0.7163707526581122, время: 13\n",
      "С: 10.0; качество: 0.7163704793048005, время: 13\n",
      "С: 100.0; качество: 0.7163704962706654, время: 13\n",
      "С: 1000.0; качество: 0.7163705301659756, время: 13\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "times = []\n",
    "\n",
    "for i in coefs:\n",
    "    clf = LogisticRegression(C=i, random_state=241)\n",
    "    \n",
    "    sum_score = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for train_index, test_index in selector.split(X):\n",
    "        clf.fit(scaled_X_nocat[train_index],y[train_index])               \n",
    "        pred = clf.predict_proba(scaled_X_nocat[test_index])[:, 1]        \n",
    "        score = roc_auc_score(y[test_index], pred)\n",
    "        sum_score += score\n",
    "        \n",
    "    time = datetime.datetime.now() - start_time\n",
    "    times.append(time)\n",
    "    \n",
    "    scores.append(sum_score / 5)\n",
    "    \n",
    "for i, s in enumerate(scores):\n",
    "    print(f\"С: {coefs[i]}; качество: {s}, время: {times[i].seconds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество практически не изменилось (0.716). Связано с маленькими весами у категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = []\n",
    "heroes = np.union1d(features[\"r1_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"r2_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"r3_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"r4_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"r5_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"d1_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"d2_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"d3_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"d4_hero\"].values, heroes)\n",
    "heroes = np.union1d(features[\"d5_hero\"].values, heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Различных идентификаторов героев: 108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Различных идентификаторов героев: {heroes.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "N = np.max(features.r2_hero.unique())\n",
    "X_pick = np.zeros((features.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick_all = np.concatenate((scaled_X_nocat,X_pick),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С: 1e-05; качество: 0.6991713216855027, время: 3\n",
      "С: 0.0001; качество: 0.725022149276278, время: 5\n",
      "С: 0.001; качество: 0.7462962333706958, время: 11\n",
      "С: 0.01; качество: 0.7517359843797606, время: 19\n",
      "С: 0.1; качество: 0.751937474938148, время: 26\n",
      "С: 1.0; качество: 0.7519195723934251, время: 27\n",
      "С: 10.0; качество: 0.7519170090246463, время: 27\n",
      "С: 100.0; качество: 0.7519172230074844, время: 27\n",
      "С: 1000.0; качество: 0.7519170387747672, время: 27\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "times = []\n",
    "\n",
    "for i in coefs:\n",
    "    clf = LogisticRegression(C=i, random_state=241)\n",
    "    \n",
    "    sum_score = 0\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for train_index, test_index in selector.split(X):\n",
    "        clf.fit(X_pick_all[train_index],y[train_index])               \n",
    "        pred = clf.predict_proba(X_pick_all[test_index])[:, 1]        \n",
    "        score = roc_auc_score(y[test_index], pred)\n",
    "        sum_score += score\n",
    "        \n",
    "    time = datetime.datetime.now() - start_time\n",
    "    times.append(time)\n",
    "    \n",
    "    scores.append(sum_score / 5)\n",
    "    \n",
    "for i, s in enumerate(scores):\n",
    "    print(f\"С: {coefs[i]}; качество: {s}, время: {times[i].seconds}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " При добавлении \"мешка слов\" качество улучшилось с 0.716 до 0.752. Это можно обЪянить тем, что при использовании категориальных признаков напрямую, они не несут никакой полезной информации для классификатора. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = pd.read_csv('./features_test.csv', index_col='match_id')\n",
    "features_test = features_test.fillna(0)\n",
    "X_test = features_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X_test_nocat = X_test\n",
    "for i in range(9,-1,-1):\n",
    "    X_test_nocat = np.delete(X_test_nocat, 2 + i * 8, 1)\n",
    "X_test_nocat =  np.delete(X_test_nocat, 1, 1)\n",
    "\n",
    "N = np.max(features_test.r2_hero.unique())\n",
    "X_test_pick = np.zeros((features_test.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(features_test.index):\n",
    "    for p in range(5):\n",
    "        X_test_pick[i, features_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_test_pick[i, features_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test_pick_all = np.concatenate((X_test_nocat,X_test_pick),axis=1)\n",
    "X_test_pick_all_scaled = scaler.fit_transform(X_test_pick_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=241, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, random_state=241)\n",
    "clf.fit(X_pick_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict_proba(X_test_pick_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное значение: 1.0, минимальное значение: 1.3e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Максимальное значение: {max(result[:,1]):.3}, минимальное значение: {min(result[:,1]):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
